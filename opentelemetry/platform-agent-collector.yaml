apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: platform-agent
  namespace: observability
  labels:
    monitoring: prometheus
spec:
  image: otel/opentelemetry-collector-contrib:latest
  mode: "daemonset"
  serviceAccount: platform-agent
  hostNetwork: false
  volumeMounts:
    - name: hostfs
      mountPath: /hostfs
      readOnly: true
      mountPropagation: HostToContainer
  volumes:
    - name: hostfs
      hostPath:
        path: /
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: OTEL_SERVICE_NAME
      value: "platform-agent"
  tolerations:
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Exists"
    effect: "NoSchedule"
  config: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:

      prometheus:
        config:
          scrape_configs:
          - job_name: otel-collector-metrics
            scrape_interval: 30s
            static_configs:
            - targets: ['${env:POD_IP}:8888']
          - job_name: 'grafana-operator'
            scrape_interval: 30s
            static_configs:
            - targets: ['grafana-operator-metrics-service.observability.svc:9090']
      
      hostmetrics:
        collection_interval: 10s
        scrapers:
          cpu:
          load:
          memory:
          disk:
          filesystem:
          network:
      
      k8s_cluster:
        collection_interval: 20s
        node_conditions_to_report: 
          - Ready
          - MemoryPressure
        allocatable_types_to_report: 
          - cpu
          - memory
          - ephemeral-storage
          - storage
      
      # Observers are implemented as an extension to discover networked endpoints like a Kubernetes pod
      receiver_creator:
        watch_observers: [k8s_observer]
        receivers:
          kubeletstats:
            rule: type == "k8s.node"
            config:
              collection_interval: 10s
              auth_type: 'serviceAccount'
              endpoint: '${env:K8S_NODE_NAME}:10250'
              insecure_skip_verify: true
              extra_metadata_labels:
                - container.id
              metric_groups:
                - node
                - pod
                - container
      
      k8s_events:
        auth_type : serviceAccount

    processors:
      batch:
        send_batch_max_size: 1000
        timeout: 30s
        send_batch_size : 800

      memory_limiter:
         check_interval: 1s
         limit_percentage: 70
         spike_limit_percentage: 30
      
      metricstransform:
        transforms:
          include: .+ # Note: '.' corresponde a qualquer caractere individual e '+' garante que pelo menos um caractere esteja presente
          match_type: regexp
          action: insert
          operations:
            - action: add_label
              new_label: k8s.cluster_name
              new_value: kind-observability-platform

      resourcedetection/k8snode:
        detectors: [k8snode]
        timeout: 2s
        override: true
      
      # k8sattributes processor to get the metadata from K8s# k8sattributes processor to get the metadata from K8s
      k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        filter:
          node_from_env_var: K8S_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time

    exporters:
      otlp:
        endpoint: tempo-grafana-distributor.observability.svc.cluster.local:4317
        tls:
          insecure: true
        sending_queue:
          num_consumers: 4
          queue_size: 100
        retry_on_failure:
          enabled: true
      
      prometheusremotewrite:
        endpoint: http://grafana-mimir-nginx.observability.svc:80/api/v1/push
        tls: 
          insecure: true
      
      # NOTE: Prior to v0.86.0 use `logging` instead of `debug`.
      debug:
    
    
    extensions:
      memory_ballast:
        size_in_percentage: 20
      #k8s_observer:
      #  auth_type: serviceAccount
      #  node: ${env:K8S_NODE_NAME}
      #  observe_pods: true
      #  observe_nodes: true

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [debug, otlp]
        metrics:
          receivers: [prometheus, hostmetrics, k8s_cluster]
          processors: [memory_limiter, metricstransform, k8sattributes, resourcedetection/k8snode, batch]
          exporters: [prometheusremotewrite]
        logs:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [debug]
